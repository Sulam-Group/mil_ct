{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "import cv2 as cv\n",
    "from scipy.stats import binom\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention-MIL model\n",
    "* Attention-MIL model basically consists of 3 sections:\n",
    "    * (1) A feature extractor, in most case it is a pretrained CNN\n",
    "    * (2) Attention Module, which is used to decide weights for all patches and aggregate them \n",
    "    * (3) Final classification, which is a one or two-layer FCN to produce the final probability score for bag\n",
    "* In the following implementation:\n",
    "    * (1) class `Attention_modern` implements 2) Attention Module and 3)Final classification and leave 1) feature extractor as the input\n",
    "    * (2) There are 3 feature extractors provided (vgg, inception and resnet). For all of them, I chose to load the pretrained version and freeze the convolutional layers\n",
    "* This is the manuscript [https://arxiv.org/abs/1802.04712] proposing MIL-attention for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg16():\n",
    "    vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "    num_layer = 0\n",
    "    for child in vgg.children():\n",
    "        num_layer+=1\n",
    "        if num_layer < 3:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False  \n",
    "    return vgg\n",
    "def load_inception():\n",
    "    inception = torch.hub.load('pytorch/vision:v0.6.0', 'inception_v3', pretrained=True)\n",
    "    num_layer = 0\n",
    "    for child in inception.children():\n",
    "        num_layer+=1\n",
    "        if num_layer < 10:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False  \n",
    "    return inception    \n",
    "def load_resnet18():\n",
    "    resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "    num_layer = 0\n",
    "    for child in resnet.children():\n",
    "        num_layer+=1\n",
    "        if num_layer < 18:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False  \n",
    "    return resnet  \n",
    "\n",
    "class Attention_modern(nn.Module):\n",
    "    def __init__(self,cnn,focal_loss=False):\n",
    "        super(Attention_modern,self).__init__()\n",
    "        self.L = 1000\n",
    "        self.D = 64\n",
    "        self.K = 1 \n",
    "        self.focal_loss = focal_loss     \n",
    "        self.feature_extractor = cnn      \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x .squeeze(0)\n",
    "        H = self.feature_extractor(x)\n",
    "        A = self.attention(H)\n",
    "        A = torch.transpose(A,1,0)\n",
    "        A = F.softmax(A,dim=1) # calculate weights\n",
    "        M = torch.mm(A,H) # Aggregate features\n",
    "        Y_prob = self.classifier(M)[0]\n",
    "        Y_hat = torch.ge(Y_prob,0.5).float()\n",
    "        return Y_prob, Y_hat, A\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, Y_hat,_ = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().data.item()\n",
    "\n",
    "        return error, Y_hat, Y_prob  \n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _, A = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        if not self.focal_loss:\n",
    "            neg_log_likelihood =-1. * (Y * torch.log(Y_prob)+(1. - Y) * torch.log(1. - Y_prob))\n",
    "        else:\n",
    "            if Y.cpu().data.numpy()[0]==0:\n",
    "                Y_prob = 1-Y_prob            \n",
    "            if Y_prob.cpu().data.numpy()[0]<0.2:\n",
    "                gamma = 5\n",
    "            else:\n",
    "                gamma = 3\n",
    "            neg_log_likelihood =-1. *(1-Y_prob)**gamma* torch.log(Y_prob)\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /cis/home/zwang/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention_modern(\n",
      "  (feature_extractor): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Attention_modern(load_vgg16(),focal_loss=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
